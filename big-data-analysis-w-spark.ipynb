{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/ibrahim/anaconda3/envs/statsenv/lib/python3.11/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/ibrahim/anaconda3/envs/statsenv/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore')\n",
    "import findspark\n",
    "findspark.init('/Users/ibrahim/spark/spark-3.5.1-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfigürasyon ve Spark Bağlantısı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/19 15:29:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.96:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark-shell>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Versiyonu için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kullanıcı Sorgusu için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ibrahim'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.sparkUser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PACKAGE_EXTENSIONS',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getnewargs__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_accumulatorServer',\n",
       " '_active_spark_context',\n",
       " '_assert_on_driver',\n",
       " '_batchSize',\n",
       " '_callsite',\n",
       " '_checkpointFile',\n",
       " '_conf',\n",
       " '_dictToJavaMap',\n",
       " '_do_init',\n",
       " '_encryption_enabled',\n",
       " '_ensure_initialized',\n",
       " '_gateway',\n",
       " '_getJavaStorageLevel',\n",
       " '_initialize_context',\n",
       " '_javaAccumulator',\n",
       " '_jsc',\n",
       " '_jvm',\n",
       " '_lock',\n",
       " '_next_accum_id',\n",
       " '_pickled_broadcast_vars',\n",
       " '_python_includes',\n",
       " '_repr_html_',\n",
       " '_serialize_to_jvm',\n",
       " '_temp_dir',\n",
       " '_unbatched_serializer',\n",
       " 'accumulator',\n",
       " 'addArchive',\n",
       " 'addFile',\n",
       " 'addJobTag',\n",
       " 'addPyFile',\n",
       " 'appName',\n",
       " 'applicationId',\n",
       " 'binaryFiles',\n",
       " 'binaryRecords',\n",
       " 'broadcast',\n",
       " 'cancelAllJobs',\n",
       " 'cancelJobGroup',\n",
       " 'cancelJobsWithTag',\n",
       " 'clearJobTags',\n",
       " 'defaultMinPartitions',\n",
       " 'defaultParallelism',\n",
       " 'dump_profiles',\n",
       " 'emptyRDD',\n",
       " 'environment',\n",
       " 'getCheckpointDir',\n",
       " 'getConf',\n",
       " 'getJobTags',\n",
       " 'getLocalProperty',\n",
       " 'getOrCreate',\n",
       " 'hadoopFile',\n",
       " 'hadoopRDD',\n",
       " 'listArchives',\n",
       " 'listFiles',\n",
       " 'master',\n",
       " 'newAPIHadoopFile',\n",
       " 'newAPIHadoopRDD',\n",
       " 'parallelize',\n",
       " 'pickleFile',\n",
       " 'profiler_collector',\n",
       " 'pythonExec',\n",
       " 'pythonVer',\n",
       " 'range',\n",
       " 'removeJobTag',\n",
       " 'resources',\n",
       " 'runJob',\n",
       " 'sequenceFile',\n",
       " 'serializer',\n",
       " 'setCheckpointDir',\n",
       " 'setInterruptOnCancel',\n",
       " 'setJobDescription',\n",
       " 'setJobGroup',\n",
       " 'setLocalProperty',\n",
       " 'setLogLevel',\n",
       " 'setSystemProperty',\n",
       " 'show_profiles',\n",
       " 'sparkHome',\n",
       " 'sparkUser',\n",
       " 'startTime',\n",
       " 'statusTracker',\n",
       " 'stop',\n",
       " 'textFile',\n",
       " 'uiWebUrl',\n",
       " 'union',\n",
       " 'version',\n",
       " 'wholeTextFiles']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Açılan Session'ı kapatmak istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "#Yukarıdaki ile kapatırız.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.96:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark-shell>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import  SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(master = \"local\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop() #sparkı durdurmadan yeni bir spark oluşturamazsınız"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal şartlarda yukarıdaki gibi Spark yapısını oluşturabiliriz fakat biz konfigüre edebilmek istersek aşağıdaki gibi yazmamız gerekir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.96:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark for practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark for practice>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession.builder  \n",
    "            .master(\"local\") \n",
    "            .appName(\"pyspark for practice\") \n",
    "            .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "sc\n",
    "# configin normalde boş bırakılması sisteme uygun bir şekilde configlenir. istersek ram ayarları gibi ayarları yapabiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temel Data Frame İşlemleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alışageldiğimiz pandas data frame'leri spark tarafında uyumsuzluğa sebep olabiliyor. Bu açıdan bundan sonra spark data frameleri üzerine çalışacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv('./diabetes.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Şema Görüntülemek İstersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: integer (nullable = true)\n",
      " |-- Glucose: integer (nullable = true)\n",
      " |-- BloodPressure: integer (nullable = true)\n",
      " |-- SkinThickness: integer (nullable = true)\n",
      " |-- Insulin: integer (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: double (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Outcome: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veriyi RAM'e taşımak istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Pregnancies: int, Glucose: int, BloodPressure: int, SkinThickness: int, Insulin: int, BMI: double, DiabetesPedigreeFunction: double, Age: int, Outcome: int]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.cache() #veriyi işlenebilir bir hale getirmek olarak da düşünebiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karşılaştırmak Üzere Python DataFrame oluşturalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset(\"diamonds\")\n",
    "df = df.select_dtypes(include=[\"float64\",\"int64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yukarıda da görüldüğü üzere pandas üzerinden bir data frame incelediğimizde pandas core üzerinde bir data frame olduğunu görebiliyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## İki tarafta da desteklenen bazı fonksiyonları incelemek istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  table  price     x     y     z\n",
       "0   0.23   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Pregnancies=6, Glucose=148, BloodPressure=72, SkinThickness=35, Insulin=0, BMI=33.6, DiabetesPedigreeFunction=0.627, Age=50, Outcome=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat    float64\n",
       "depth    float64\n",
       "table    float64\n",
       "price      int64\n",
       "x        float64\n",
       "y        float64\n",
       "z        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pregnancies', 'int'),\n",
       " ('Glucose', 'int'),\n",
       " ('BloodPressure', 'int'),\n",
       " ('SkinThickness', 'int'),\n",
       " ('Insulin', 'int'),\n",
       " ('BMI', 'double'),\n",
       " ('DiabetesPedigreeFunction', 'double'),\n",
       " ('Age', 'int'),\n",
       " ('Outcome', 'int')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\n",
      "File \u001b[0;32m~/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/dataframe.py:3127\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3094\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m \n\u001b[1;32m   3096\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3124\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 3127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   3128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   3129\u001b[0m     )\n\u001b[1;32m   3130\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   3131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ndim'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/19 15:29:15 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark_df.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Görüldüğü üzere numpy üzerinden boyut bildirgesi almak için kullandığımız ndim fonksiyonunu spark'da kullanamıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aynı durum size için de geçerli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\n",
      "File \u001b[0;32m~/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/dataframe.py:3127\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3094\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m \n\u001b[1;32m   3096\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3124\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 3127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   3128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   3129\u001b[0m     )\n\u001b[1;32m   3130\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   3131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "spark_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame'i paralel çalışmaz fakat PySpark DataFrame'i paralel çalışabilir. Bu açıdan büyük olarak sınıflandırılan verileri hızlıca analiz edebilme olanağı sağlar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Tarafında Kullanabileceğimiz DataFrame İşlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(2)\n",
    "#yukarıdaki show fonksiyonu veriyi bir tablo şeklinde görmemizi sağlar\n",
    "#gözlem sayısını belirtiriz ve 2 olarak belirttiğimiz için her sütunun 2 gözlemini göstermektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
      "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
      "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
      "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1|\n",
      "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|\n",
      "|         10|    168|           74|            0|      0|38.0|                   0.537| 34|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verisetindeki toplam gözlem sayısını görmek istersek aşağıdaki fonksiyonu kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verisetindeki değişkenlerin isimlerini ulaşmak istersek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age',\n",
       " 'Outcome']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spark_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verisetinin özetini görmek istersek alışık olduğumuz biçimde pandas'ta describe() fonksiyonunu çağırırdık. Burada ise sonuna show eklemeliyiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "|summary|       Pregnancies|          Glucose|     BloodPressure|     SkinThickness|           Insulin|               BMI|DiabetesPedigreeFunction|               Age|           Outcome|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "|  count|               768|              768|               768|               768|               768|               768|                     768|               768|               768|\n",
      "|   mean|3.8450520833333335|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.992578124999977|      0.4718763020833327|33.240885416666664|0.3489583333333333|\n",
      "| stddev|  3.36957806269887|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803| 7.884160320375441|       0.331328595012775|11.760231540678689| 0.476951377242799|\n",
      "|    min|                 0|                0|                 0|                 0|                 0|               0.0|                   0.078|                21|                 0|\n",
      "|    max|                17|              199|               122|                99|               846|              67.1|                    2.42|                81|                 1|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## İstediğimiz bir kategorik değişken üzerinde describe kullanmak istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|       Pregnancies|\n",
      "+-------+------------------+\n",
      "|  count|               768|\n",
      "|   mean|3.8450520833333335|\n",
      "| stddev|  3.36957806269887|\n",
      "|    min|                 0|\n",
      "|    max|                17|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe(\"Pregnancies\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Değişken seçmek istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Glucose|\n",
      "+-------+\n",
      "|    148|\n",
      "|     85|\n",
      "+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select(\"Glucose\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas'ta değişken seçerken df[\"X\"] yazarak değişken seçerdik Spark'da ise select fonksiyonunun içine belirtememiz gerekiyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|Glucose|Pregnancies|\n",
      "+-------+-----------+\n",
      "|    148|          6|\n",
      "|     85|          1|\n",
      "+-------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select(\"Glucose\",\"Pregnancies\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eşsiz Gözlemlere ulaşmak istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.select(\"Glucose\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bir değişkenin içerisindeki birbirini tekrar eden değerleri silip görmek istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Glucose|\n",
      "+-------+\n",
      "|    148|\n",
      "|     85|\n",
      "|    137|\n",
      "|     65|\n",
      "|    133|\n",
      "|     78|\n",
      "|    155|\n",
      "|    108|\n",
      "|    193|\n",
      "|    115|\n",
      "|    126|\n",
      "|    101|\n",
      "|     81|\n",
      "|    183|\n",
      "|     76|\n",
      "|    159|\n",
      "|     44|\n",
      "|    103|\n",
      "|     91|\n",
      "|    128|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select(\"Glucose\").dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.select(\"Glucose\").dropDuplicates().count()\n",
    "# Eşsiz değerler elimizde kaldı ve sayısını da görebiliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|Outcome_Pregnancies|  0|  1| 10| 11| 12| 13| 14| 15| 17|  2|  3|  4|  5|  6|  7|  8|  9|\n",
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|                  0| 73|106| 14|  4|  5|  5|  0|  0|  0| 84| 48| 45| 36| 34| 20| 16| 10|\n",
      "|                  1| 38| 29| 10|  7|  4|  5|  2|  1|  1| 19| 27| 23| 21| 16| 25| 22| 18|\n",
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.crosstab(\"Outcome\",\"Pregnancies\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksik gözlemlerden kurtulmak ve onları göstermek istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.dropna().count()\n",
    "#çıktıdan da görüldüğü üzere verisetimizde eksik gözlem yokmuş"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
      "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
      "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
      "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1|\n",
      "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|\n",
      "|         10|    168|           74|            0|      0|38.0|                   0.537| 34|      1|\n",
      "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|\n",
      "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
      "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
      "|          7|    100|            0|            0|      0|30.0|                   0.484| 32|      1|\n",
      "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
      "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1|\n",
      "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
      "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.dropna().show()\n",
    "#Eğer veri setimizde eksik veriler olsaydı temizlenecekti ve gösterilecekti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gözlem Seçmek ve Filtrelemek İstersek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aşağıda yaşı 40'tan büyük olanları filtrelemiş olduk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.filter(spark_df.Age > 40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1|\n",
      "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|\n",
      "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
      "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
      "|          8|     99|           84|            0|      0|35.4|                   0.388| 50|      0|\n",
      "|          7|    196|           90|            0|      0|39.8|                   0.451| 41|      1|\n",
      "|         11|    143|           94|           33|    146|36.6|                   0.254| 51|      1|\n",
      "|         10|    125|           70|           26|    115|31.1|                   0.205| 41|      1|\n",
      "|          7|    147|           76|            0|      0|39.4|                   0.257| 43|      1|\n",
      "|         13|    145|           82|           19|    110|22.2|                   0.245| 57|      0|\n",
      "|          5|    109|           75|           26|      0|36.0|                   0.546| 60|      0|\n",
      "|         10|    122|           78|           31|      0|27.6|                   0.512| 45|      0|\n",
      "|          9|    102|           76|           37|      0|32.9|                   0.665| 46|      1|\n",
      "|          4|    111|           72|           47|    207|37.1|                    1.39| 56|      1|\n",
      "|          7|    106|           92|           18|      0|22.7|                   0.235| 48|      0|\n",
      "|          9|    171|          110|           24|    240|45.4|                   0.721| 54|      1|\n",
      "|          8|    176|           90|           34|    300|33.7|                   0.467| 58|      1|\n",
      "|          7|    150|           66|           42|    342|34.7|                   0.718| 42|      0|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.filter(spark_df.Age > 40).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gruplama İşlemleri yapmak istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|OutCome|count|\n",
      "+-------+-----+\n",
      "|      1|  268|\n",
      "|      0|  500|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"OutCome\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gruplama işlemlerinin yanında kapsamlı agg işlemleri yapmak istersek aşağıdaki gibi yapabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|OutCome|         avg(BMI)|\n",
      "+-------+-----------------+\n",
      "|      1|35.14253731343278|\n",
      "|      0|30.30419999999996|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"OutCome\").agg({\"BMI\":\"mean\"}).show()\n",
    "#ortalamasını aldık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|OutCome|      stddev(BMI)|\n",
      "+-------+-----------------+\n",
      "|      1|7.262967242346374|\n",
      "|      0|7.689855011650116|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"OutCome\").agg({\"BMI\":\"std\"}).show()\n",
    "#standart sapmasını aldık"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Değişken ekleme ve değişken silme ihtiyaçlarımızı aşağıdaki gibi karşılayabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "| BMI|yeni_degisken|\n",
      "+----+-------------+\n",
      "|33.6|         16.8|\n",
      "|26.6|         13.3|\n",
      "|23.3|        11.65|\n",
      "|28.1|        14.05|\n",
      "|43.1|        21.55|\n",
      "+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.withColumn(\"yeni_degisken\", spark_df.BMI / 2).select(\"BMI\",\"yeni_degisken\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herhangi bir değişkenin ismini değiştirmek istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age',\n",
       " 'bagimli_degisken']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.withColumnRenamed(\"Outcome\",\"bagimli_degisken\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+----------------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|bagimli_degisken|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+----------------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|               1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|               0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|               1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|               0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|               1|\n",
      "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|               0|\n",
      "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|               1|\n",
      "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|               0|\n",
      "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|               1|\n",
      "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|               1|\n",
      "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|               0|\n",
      "|         10|    168|           74|            0|      0|38.0|                   0.537| 34|               1|\n",
      "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|               0|\n",
      "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|               1|\n",
      "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|               1|\n",
      "|          7|    100|            0|            0|      0|30.0|                   0.484| 32|               1|\n",
      "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|               1|\n",
      "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|               1|\n",
      "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|               0|\n",
      "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|               1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.withColumnRenamed(\"Outcome\",\"bagimli_degisken\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bir değişkeni silmek istersek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
      "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
      "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
      "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1|\n",
      "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|\n",
      "|         10|    168|           74|            0|      0|38.0|                   0.537| 34|      1|\n",
      "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|\n",
      "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
      "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
      "|          7|    100|            0|            0|      0|30.0|                   0.484| 32|      1|\n",
      "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
      "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1|\n",
      "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
      "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age',\n",
       " 'Outcome']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.drop(\"Insulin\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|43.1|                   2.288| 33|      1|\n",
      "|          5|    116|           74|            0|25.6|                   0.201| 30|      0|\n",
      "|          3|     78|           50|           32|31.0|                   0.248| 26|      1|\n",
      "|         10|    115|            0|            0|35.3|                   0.134| 29|      0|\n",
      "|          2|    197|           70|           45|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0| 0.0|                   0.232| 54|      1|\n",
      "|          4|    110|           92|            0|37.6|                   0.191| 30|      0|\n",
      "|         10|    168|           74|            0|38.0|                   0.537| 34|      1|\n",
      "|         10|    139|           80|            0|27.1|                   1.441| 57|      0|\n",
      "|          1|    189|           60|           23|30.1|                   0.398| 59|      1|\n",
      "|          5|    166|           72|           19|25.8|                   0.587| 51|      1|\n",
      "|          7|    100|            0|            0|30.0|                   0.484| 32|      1|\n",
      "|          0|    118|           84|           47|45.8|                   0.551| 31|      1|\n",
      "|          7|    107|           74|            0|29.6|                   0.254| 31|      1|\n",
      "|          1|    103|           30|           38|43.3|                   0.183| 33|      0|\n",
      "|          1|    115|           70|           30|34.6|                   0.529| 32|      1|\n",
      "+-----------+-------+-------------+-------------+----+------------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.drop(\"Insulin\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark tarafındaki veri yapısını pandasa çevirmek istersek toPandas() fonksiyonunu kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome  count\n",
       "0        1    268\n",
       "1        0    500"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.groupBy(\"Outcome\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = spark_df.groupBy(\"Outcome\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome  count\n",
       "0        1    268\n",
       "1        0    500"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome\n",
       "0        1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.iloc[0:1,0:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
